{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_trainer import run_wandb_training, run_training_without_logging\n",
    "from energy_model.energy_model import EnergyModel\n",
    "from model_trainer import Antolik_dataset_preparation_function\n",
    "from utils import get_config\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ENTITY = \"csng-cuni\"\n",
    "PROJECT = \"reCNN_visual_prosthesis\"\n",
    "model = None\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "train_on_test = False\n",
    "max_epochs = 1\n",
    "max_time = 0\n",
    "patience = 7\n",
    "train_on_val = False\n",
    "test = True\n",
    "seed = 42\n",
    "batch_size = 10\n",
    "lr = 0.001\n",
    "\n",
    "def main():\n",
    "\n",
    "    config = get_config(model=\"EM\")\n",
    "\n",
    "    # TRAINING PARAMETERS\n",
    "    config[\"train_on_test\"] = train_on_test\n",
    "    config[\"max_epochs\"] = max_epochs\n",
    "    config[\"max_time\"] = max_time\n",
    "    config[\"patience\"] = patience\n",
    "    config[\"train_on_val\"] = train_on_val\n",
    "    config[\"test\"] = test\n",
    "    config[\"seed\"] = seed\n",
    "    config[\"batch_size\"] = batch_size\n",
    "    config[\"lr\"] = lr\n",
    "    \n",
    "    config[\"train_data_dir\"] = \"/storage/brno2/home/mpicek/reCNN_visual_prosthesis/data/antolik_reparametrized_small/one_trials.pickle\"\n",
    "    config[\"test_data_dir\"] = \"/storage/brno2/home/mpicek/reCNN_visual_prosthesis/data/antolik_reparametrized_small/ten_trials.pickle\"\n",
    "\n",
    "    model = run_wandb_training(\n",
    "        config,\n",
    "        Antolik_dataset_preparation_function,\n",
    "        ENTITY,\n",
    "        PROJECT,\n",
    "        model_class=EnergyModel\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcsng-cuni\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/csng-cuni/reCNN_visual_prosthesis/runs/697a8i3r\" target=\"_blank\">atomic-elevator-422</a></strong> to <a href=\"https://wandb.ai/csng-cuni/reCNN_visual_prosthesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10,\n",
      " 'bias_init': 2.5,\n",
      " 'bottleneck_kernel': 15,\n",
      " 'brain_crop': None,\n",
      " 'compute_oracle_fraction': False,\n",
      " 'conservative_oracle': True,\n",
      " 'core_gamma_hidden': 0.28463619129195233,\n",
      " 'core_gamma_input': 0.00307424496692959,\n",
      " 'core_hidden_channels': 3,\n",
      " 'core_hidden_kern': 3,\n",
      " 'core_input_kern': 3,\n",
      " 'core_layers': 1,\n",
      " 'counter_clockwise_rotation': True,\n",
      " 'dataset_artifact_name': 'Antolik_dataset:latest',\n",
      " 'default_ori_shift': 90,\n",
      " 'depth_separable': True,\n",
      " 'do_not_sample': True,\n",
      " 'em_bias': True,\n",
      " 'exact_init': True,\n",
      " 'f_init': 0.63,\n",
      " 'factor': 5.5,\n",
      " 'fixed_sigma': False,\n",
      " 'freeze_orientations': False,\n",
      " 'freeze_positions': False,\n",
      " 'generate_oracle_figure': False,\n",
      " 'ground_truth_orientations_file_path': 'data/antolik/oris_reparametrized.pickle',\n",
      " 'ground_truth_positions_file_path': 'data/antolik/positions_reparametrized.pickle',\n",
      " 'init_mu_range': 0.3,\n",
      " 'init_sigma_range': 0.1,\n",
      " 'init_to_ground_truth_orientations': True,\n",
      " 'init_to_ground_truth_positions': True,\n",
      " 'input_regularizer': 'LaplaceL2norm',\n",
      " 'jackknife_oracle': True,\n",
      " 'lr': 0.001,\n",
      " 'max_epochs': 1,\n",
      " 'max_time': 0,\n",
      " 'model_needs_dataloader': False,\n",
      " 'multivariate': True,\n",
      " 'needs_ground_truth': True,\n",
      " 'nonlinearity': 'softplus',\n",
      " 'normalize': True,\n",
      " 'num_bins': 100,\n",
      " 'num_rotations': 4,\n",
      " 'observed_val_metric': 'val/corr',\n",
      " 'orientation_shift': 87.4,\n",
      " 'patience': 7,\n",
      " 'positions_minus_x': False,\n",
      " 'positions_minus_y': True,\n",
      " 'positions_swap_axes': False,\n",
      " 'readout_bias': False,\n",
      " 'readout_gamma': 0.17,\n",
      " 'reg_group_sparsity': 0.1,\n",
      " 'reg_readout_spatial_smoothness': 0.0027,\n",
      " 'reg_spatial_sparsity': 0.45,\n",
      " 'rot_eq_batch_norm': True,\n",
      " 'sample': False,\n",
      " 'scale_init': 0.3,\n",
      " 'seed': 42,\n",
      " 'sigma_x_init': 0.56,\n",
      " 'sigma_y_init': 0.67,\n",
      " 'smooth_reg_weight': 0.0014451681045518333,\n",
      " 'smoothness_reg_order': 3,\n",
      " 'stack': -1,\n",
      " 'stimulus_crop': None,\n",
      " 'stride': 1,\n",
      " 'test': True,\n",
      " 'test_average_batch': False,\n",
      " 'test_data_dir': '/storage/brno2/home/mpicek/reCNN_visual_prosthesis/data/antolik_reparametrized_small/ten_trials.pickle',\n",
      " 'train_data_dir': '/storage/brno2/home/mpicek/reCNN_visual_prosthesis/data/antolik_reparametrized_small/one_trials.pickle',\n",
      " 'train_on_test': False,\n",
      " 'train_on_val': False,\n",
      " 'upsampling': 2,\n",
      " 'use_avg_reg': True,\n",
      " 'val_size': 5000,\n",
      " 'vmax': 100}\n",
      "Setting up the dataset...\n",
      "Data loaded successfully!\n",
      "Loaded precomputed mean from /storage/brno2/home/mpicek/reCNN_visual_prosthesis/data/antolik_reparametrized_small/one_trials_mean.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/neuralpredictors/measures/modules.py:78: UserWarning: Poissonloss is averaged per batch. It's recommended to use `sum` instead\n",
      "  warnings.warn(\"Poissonloss is averaged per batch. It's recommended to use `sum` instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:341: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atomic-elevator-422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-5b853da0-9a2b-1269-af6f-2ffe3bdf2e81]\n",
      "\n",
      "  | Name   | Type                           | Params\n",
      "----------------------------------------------------------\n",
      "0 | loss   | PoissonLoss                    | 0     \n",
      "1 | corr   | Corr                           | 0     \n",
      "2 | nonlin | PiecewiseLinearExpNonlinearity | 203   \n",
      "----------------------------------------------------------\n",
      "107       Trainable params\n",
      "102       Non-trainable params\n",
      "209       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:452: UserWarning: Your `val_dataloader` has `shuffle=True`,it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:11<00:11, 11.20s/it]0.07180692\n",
      "0.07180692\n",
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████▉| 4495/4500 [03:04<00:00, 24.32it/s, loss=-0.327, v_num=8i3r]  0.1275436\n",
      "0.1275436\n",
      "Epoch 0: 100%|██████████| 4500/4500 [03:06<00:00, 24.09it/s, loss=-0.327, v_num=8i3r]\n",
      "Best model's val/corr: 0.1275436\n",
      "EnergyModel\n",
      "<wandb.sdk.wandb_artifacts.Artifact object at 0x151d7cb0c700>\n",
      "/auto/brno2/home/mpicek/MODEL_CHECKPOINTS/atomic-elevator-422/epoch=0-step=3999.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-5b853da0-9a2b-1269-af6f-2ffe3bdf2e81]\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:452: UserWarning: Your `test_dataloader` has `shuffle=True`,it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 500/500 [00:07<00:00, 66.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-5b853da0-9a2b-1269-af6f-2ffe3bdf2e81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 500/500 [00:07<00:00, 67.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [GPU-5b853da0-9a2b-1269-af6f-2ffe3bdf2e81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 500/500 [00:06<00:00, 72.41it/s]\n",
      "Validation dataset:\n",
      "    Correlation: 0.1275 \n",
      "Test dataset with averaged responses of repeated trials:\n",
      "    Correlation: 0.1968 \n",
      "    Fraction oracle conservative: 0.3349 \n",
      "    Fraction oracle jackknife: 0.4150 \n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
