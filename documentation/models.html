<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>models API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>models</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from predict_neural_responses.models import *
from utils import get_fraction_oracles
import predict_neural_responses.dnn_blocks.dnn_blocks as bl

from torch import nn
import torch
from collections import OrderedDict

from neuralpredictors.layers.hermite import (
    HermiteConv2D,
)
from neuralpredictors.measures.np_functions import corr as corr_from_neuralpredictors
from neuralpredictors.measures.np_functions import (
    oracle_corr_jackknife,
    oracle_corr_conservative,
)
from neuralpredictors.layers.cores.conv2d import RotationEquivariant2dCore

import logging

from readout import Gaussian3dCyclic
from core import RotationEquivariant2dCoreBottleneck

logger = logging.getLogger(__name__)


class ExtendedEncodingModel(encoding_model):
    &#34;&#34;&#34;Parent class for system identification enconding models, keeps track of useful metrics

    In config:
        - test_average_batch: whether to average responses in batches when computing
            the test set correlation (used in repeated trials to cancel the neural variability)
        - compute_oracle_fraction: whether to compute oracle fraction or not
        - conservative_oracle: whether to compute conservative oracle or not
        - jackknife_oracle: whether to compute jackknife oracle or not
        - generate_oracle_figure: whether to generate a figure of fitted line
            describing the oracle fraction or not
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__()
        self.config = config
        self.test_average_batch = config[&#34;test_average_batch&#34;]
        self.compute_oracle_fraction = config[&#34;compute_oracle_fraction&#34;]
        self.conservative_oracle = config[&#34;conservative_oracle&#34;]
        self.jackknife_oracle = config[&#34;jackknife_oracle&#34;]
        self.generate_oracle_figure = config[&#34;generate_oracle_figure&#34;]
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.save_hyperparameters()

    def regularization(self):
        return 0

    def training_step(self, batch, batch_idx):
        &#34;&#34;&#34;Defines what to do at each training step.
        Gets the batch, passes it through the network, updates weights,
        computes loss and regularization, logs important metrics and
        returns regularized loss.

        Args:
            batch (tuple): tuple of (imgs, responses)
            batch_idx (int): Index of the batch

        Returns:
            float: Regularized loss
        &#34;&#34;&#34;
        img, resp = batch
        prediction = self.forward(img)
        loss = self.loss(prediction, resp)
        reg_term = self.regularization()
        regularized_loss = loss + reg_term
        self.log(&#34;train/unregularized_loss&#34;, loss)
        self.log(&#34;train/regularization&#34;, reg_term)
        self.log(&#34;train/regularized_loss&#34;, regularized_loss)
        return regularized_loss

    def validation_step(self, batch, batch_idx):
        &#34;&#34;&#34;Defines what to do at each validation step.
        We just get prediction and return them with target. Later in self.validation_epoch_end,
        we compute the correlation on the whole validation set (and not on separate
        batches with final averaging)

        Args:
            batch (tuple): tuple of (imgs, responses)
            batch_idx (int): Index of the batch

        Returns:
            tuple: (prediction of responses, true responses)
        &#34;&#34;&#34;        

        img, resp = batch
        prediction = self.forward(img)
        loss = self.loss(prediction, resp)
        self.log(&#34;val/loss&#34;, loss)

        return prediction, resp

    def test_step(self, batch, batch_idx):
        &#34;&#34;&#34;
        - If self.test_average_batch == True, then we average the responses of
            the batch (because it is the same image shown multiple times to cancel
            out the noise)

        - We just get prediction and return them with target. Later in validation_epoch_end,
            we compute the correlation on the whole validation set (and not on separate
            batches with final averaging).

        Args:
            batch (tuple): tuple of (imgs, responses). The images might be all the
                same in case of the oracle dataset for evaluation of the averaged trial correlation.
            batch_idx (int): Index of the batch

        Returns:
            tuple: (prediction of responses, true responses of each trial (might be averaged), true responses of each trial (never averaged))
        &#34;&#34;&#34;

        img, resp = batch
        responses_no_mean = resp

        if self.test_average_batch:
            # I take only one image as all images are the same (it is a repeated trial)
            # .unsqueeze(0) adds one dimension at the beginning (because I need
            # to create a batch of size 1)
            img = img[0].unsqueeze(0)
            resp = resp.mean(0).unsqueeze(0)

        prediction = self.forward(img)
        return prediction, resp, responses_no_mean

    def configure_optimizers(self):
        &#34;&#34;&#34;Configures the optimizer for the training of the model (Adam).

        Returns:
            torch.optimizer: torch optimizer class
        &#34;&#34;&#34;
        opt = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
        return opt

    def test_epoch_end(self, test_outs):
        &#34;&#34;&#34;We compute a correlation on the WHOLE test set. Predictions with target
        responses are in test_outs (= what each self.test_step() returned)

        Args:
            test_outs (list): What each self.test_step() returned
        &#34;&#34;&#34;
        pred = []
        resp = []
        batch_of_responses = []
        num_of_repeats = None
        for (p, r, r_batches) in test_outs:

            # The number of repeats in the repeated trials have to be the same.
            # We will use the first batch as an indicator, how many trials should
            # be in every batch. If some batch does not have the same number of
            # repeats, we discard the batch
            if num_of_repeats == None:
                num_of_repeats = r_batches.shape[0]

            pred.append(p.detach().cpu().numpy())
            resp.append(r.detach().cpu().numpy())

            if (
                r_batches.shape[0] == num_of_repeats and self.compute_oracle_fraction
            ):  # does not have the appropriate number of repeats
                batch_of_responses.append(r_batches.detach().cpu().numpy())

        predictions = np.concatenate(pred)
        responses = np.concatenate(resp)
        correlation = corr_from_neuralpredictors(predictions, responses, axis=0)

        batches_of_responses = None
        if self.compute_oracle_fraction:
            batches_of_responses = np.stack(batch_of_responses)

        if self.test_average_batch:
            self.log(&#34;test/repeated_trials/corr&#34;, np.mean(correlation))
        else:
            self.log(&#34;test/corr&#34;, np.mean(correlation))

        if self.compute_oracle_fraction:
            if self.jackknife_oracle:
                oracles = oracle_corr_jackknife(batches_of_responses)
                fraction_of_oracles = get_fraction_oracles(
                    oracles,
                    correlation,
                    generate_figure=self.generate_oracle_figure,
                    oracle_label=&#34;Oracles jackknife&#34;,
                    fig_name=&#34;oracle_jackknife.png&#34;,
                )
                self.log(&#34;test/fraction_oracle_jackknife&#34;, fraction_of_oracles[0])

            if self.conservative_oracle:
                oracles = oracle_corr_conservative(batches_of_responses)
                fraction_of_oracles = get_fraction_oracles(
                    oracles,
                    correlation,
                    generate_figure=self.generate_oracle_figure,
                    oracle_label=&#34;Oracles conservative&#34;,
                    fig_name=&#34;oracle_conservative.png&#34;,
                )
                self.log(&#34;test/fraction_oracle_conservative&#34;, fraction_of_oracles[0])

    def validation_epoch_end(self, val_outs):
        &#34;&#34;&#34;We compute the correlation on the whole set. Predictions with target
        responses are in val_outs (= what each val_step() returned)

        Args:
            val_outs (list): What each self.validation_step() returned
        &#34;&#34;&#34;        
        pred = []
        resp = []
        for (p, r) in val_outs:
            pred.append(p.detach().cpu().numpy())
            resp.append(r.detach().cpu().numpy())

        predictions = np.concatenate(pred)
        responses = np.concatenate(resp)
        correlation = corr_from_neuralpredictors(predictions, responses, axis=0)
        self.log(&#34;val/corr&#34;, np.mean(correlation))


class reCNN_FullFactorized(ExtendedEncodingModel):
    &#34;&#34;&#34;Rotation-equivariant CNN with a Full factorized readout.
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = cores.RotationEquivariant2dCore(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullFactorized2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;]
                * self.config[&#34;num_rotations&#34;]
                * abs(self.config[&#34;stack&#34;]),
                self.config[
                    &#34;input_size_x&#34;
                ],  # ocividne se to padduje, takze to neztraci rozmery
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            spatial_and_feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_FullFactorized2d&#34;

    def reg_readout_spatial_smoothness(self):
        nw = self.readout.normalized_spatial()
        reg_term = torch.sqrt(
            torch.sum(
                torch.pow(
                    nn.functional.conv2d(
                        nw.reshape(
                            self.config[&#34;num_neurons&#34;],
                            1,
                            self.config[&#34;input_size_x&#34;],
                            self.config[&#34;input_size_y&#34;],
                        ),
                        self.laplace,
                        padding=&#34;same&#34;,
                    ),
                    2,
                )
            )
        )
        reg_term = self.config[&#34;reg_readout_spatial_smoothness&#34;] * reg_term
        return reg_term

    def reg_readout_group_sparsity(self):
        nw = self.readout.normalized_spatial().reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def reg_readout_spatial_sparsity(self):
        nw = self.readout.normalized_spatial()
        reg_term = self.config[&#34;reg_spatial_sparsity&#34;] * torch.abs(nw).mean()
        self.log(&#34;reg/readout_spatial_sparsity&#34;, reg_term)
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
        spatial_smoothness = self.reg_readout_spatial_smoothness()
        group_sparsity = self.reg_readout_group_sparsity()
        spatial_sparsity = self.reg_readout_spatial_sparsity()
        self.log(&#34;reg/readout_spatial_smoothness&#34;, spatial_smoothness)
        self.log(&#34;reg/readout_group_sparsity&#34;, group_sparsity)
        self.log(&#34;reg/readout_spatial_sparsity&#34;, spatial_sparsity)

        readout_reg = (
            readout_l1_reg + spatial_smoothness + group_sparsity + spatial_sparsity
        )
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term


class reCNN_Gauss2D(ExtendedEncodingModel):
    &#34;&#34;&#34;Rotation-equivariant CNN with a 2d Gaussian readout.
    &#34;&#34;&#34;
    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = RotationEquivariant2dCore(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;]
                * self.config[&#34;num_rotations&#34;]
                * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_FullGaussian2d&#34;

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term


class reCNN_bottleneck_Gauss2d(ExtendedEncodingModel):
    &#34;&#34;&#34;
    DNN network composed of reCNN core, bottleneck at the end,
    and also a FullGaussian2d readout
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;num_rotations&#34;],
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_Gauss2d&#34;

    def add_bottleneck(self):

        layer = OrderedDict()

        if self.hidden_padding is None:
            self.hidden_padding = self.bottleneck_kernel // 2

        layer[&#34;hermite_conv&#34;] = HermiteConv2D(
            input_features=self.config[&#34;hidden_channels&#34;]
            * self.config[&#34;num_rotations&#34;],
            output_features=1,
            num_rotations=self.config[&#34;num_rotations&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            filter_size=self.config[&#34;bottleneck_kernel&#34;],
            stride=self.config[&#34;stride&#34;],
            padding=self.hidden_padding,
            first_layer=False,
        )
        super().add_bn_layer(layer)
        super().add_activation(layer)
        super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg

        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term


class reCNN_bottleneck_NoReadout(ExtendedEncodingModel):
    &#34;&#34;&#34;
    Lurz&#39;s model with RotEq core and with bottleneck
    No Readout is present here. It is used to test that the features are
        really rotation equivariant (in bottleneck_test.py)
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_NoReadout&#34;

    def regularization(self):

        readout_reg = 0
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        return reg_term


class LurzReimplementation(ExtendedEncodingModel):
    &#34;&#34;&#34;Reimplementation of the original Lurz&#39;s model.&#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = cores.SE2dCore(
            stride=self.config[&#34;stride&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],  # 0
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],  # 0
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;] * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;StackedCore_FullGaussian2d&#34;

    def reg_readout_group_sparsity(self):
        nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term


class reCNN_bottleneck_CyclicGauss3d(ExtendedEncodingModel):
    &#34;&#34;&#34;
        The main model of this repository.
        This model consists of:
            - a core with reCNN architecture with a bottleneck in the last layer
              to return only one scalar value for each position and orientation
              (meaning that the number of channels in the last layer is limited
              to 1)
            - a readout which is a Gaussian 3d readout but modified in a way
              that ensures that the third dimension (= orientation dimension)
              is periodic
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.readout = Gaussian3dCyclic(
            in_shape=(
                self.config[&#34;num_rotations&#34;],
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
            init_sigma_range=self.config[&#34;init_sigma_range&#34;],
            init_mu_range=self.config[&#34;init_mu_range&#34;],
            fixed_sigma=self.config[&#34;fixed_sigma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        self.log(&#34;train/sigma1&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma1b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        self.log(&#34;train/sigma2&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma2b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        self.log(&#34;train/sigma3&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma3b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        # print(self.readout.sigma.shape)
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_CyclicGauss3d&#34;

    def add_bottleneck(self):

        layer = OrderedDict()

        if self.hidden_padding is None:
            self.hidden_padding = self.bottleneck_kernel // 2

        layer[&#34;hermite_conv&#34;] = HermiteConv2D(
            input_features=self.config[&#34;hidden_channels&#34;]
            * self.config[&#34;num_rotations&#34;],
            output_features=1,
            num_rotations=self.config[&#34;num_rotations&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            filter_size=self.config[&#34;bottleneck_kernel&#34;],
            stride=self.config[&#34;stride&#34;],
            padding=self.hidden_padding,
            first_layer=False,
        )
        super().add_bn_layer(layer)
        super().add_activation(layer)
        super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg

        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term


class Lurz_Control_Model(ExtendedEncodingModel):
    &#34;&#34;&#34;Lurz&#39;s model used as a control model&#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        # self.loss = PoissonLoss(avg=True)
        # self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]
        

        self.core = cores.SE2dCore(
            stride=self.config[&#34;stride&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;], # 0
            gamma_hidden=config[&#34;core_gamma_hidden&#34;], # 0
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;]
        )

        
        self.readout = readouts.FullGaussian2d(
            in_shape=( #TODO: stack???
                #TODO: ten shape si potvrdit
                self.config[&#34;core_hidden_channels&#34;] * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;], # ocividne se to padduje, takze to neztraci rozmery
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x
    
    def __str__(self):
        return &#34;StackedCore_FullGaussian2d&#34;
    

    def reg_readout_group_sparsity(self):
        nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="models.ExtendedEncodingModel"><code class="flex name class">
<span>class <span class="ident">ExtendedEncodingModel</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Parent class for system identification enconding models, keeps track of useful metrics</p>
<p>In config:
- test_average_batch: whether to average responses in batches when computing
the test set correlation (used in repeated trials to cancel the neural variability)
- compute_oracle_fraction: whether to compute oracle fraction or not
- conservative_oracle: whether to compute conservative oracle or not
- jackknife_oracle: whether to compute jackknife oracle or not
- generate_oracle_figure: whether to generate a figure of fitted line
describing the oracle fraction or not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExtendedEncodingModel(encoding_model):
    &#34;&#34;&#34;Parent class for system identification enconding models, keeps track of useful metrics

    In config:
        - test_average_batch: whether to average responses in batches when computing
            the test set correlation (used in repeated trials to cancel the neural variability)
        - compute_oracle_fraction: whether to compute oracle fraction or not
        - conservative_oracle: whether to compute conservative oracle or not
        - jackknife_oracle: whether to compute jackknife oracle or not
        - generate_oracle_figure: whether to generate a figure of fitted line
            describing the oracle fraction or not
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__()
        self.config = config
        self.test_average_batch = config[&#34;test_average_batch&#34;]
        self.compute_oracle_fraction = config[&#34;compute_oracle_fraction&#34;]
        self.conservative_oracle = config[&#34;conservative_oracle&#34;]
        self.jackknife_oracle = config[&#34;jackknife_oracle&#34;]
        self.generate_oracle_figure = config[&#34;generate_oracle_figure&#34;]
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.save_hyperparameters()

    def regularization(self):
        return 0

    def training_step(self, batch, batch_idx):
        &#34;&#34;&#34;Defines what to do at each training step.
        Gets the batch, passes it through the network, updates weights,
        computes loss and regularization, logs important metrics and
        returns regularized loss.

        Args:
            batch (tuple): tuple of (imgs, responses)
            batch_idx (int): Index of the batch

        Returns:
            float: Regularized loss
        &#34;&#34;&#34;
        img, resp = batch
        prediction = self.forward(img)
        loss = self.loss(prediction, resp)
        reg_term = self.regularization()
        regularized_loss = loss + reg_term
        self.log(&#34;train/unregularized_loss&#34;, loss)
        self.log(&#34;train/regularization&#34;, reg_term)
        self.log(&#34;train/regularized_loss&#34;, regularized_loss)
        return regularized_loss

    def validation_step(self, batch, batch_idx):
        &#34;&#34;&#34;Defines what to do at each validation step.
        We just get prediction and return them with target. Later in self.validation_epoch_end,
        we compute the correlation on the whole validation set (and not on separate
        batches with final averaging)

        Args:
            batch (tuple): tuple of (imgs, responses)
            batch_idx (int): Index of the batch

        Returns:
            tuple: (prediction of responses, true responses)
        &#34;&#34;&#34;        

        img, resp = batch
        prediction = self.forward(img)
        loss = self.loss(prediction, resp)
        self.log(&#34;val/loss&#34;, loss)

        return prediction, resp

    def test_step(self, batch, batch_idx):
        &#34;&#34;&#34;
        - If self.test_average_batch == True, then we average the responses of
            the batch (because it is the same image shown multiple times to cancel
            out the noise)

        - We just get prediction and return them with target. Later in validation_epoch_end,
            we compute the correlation on the whole validation set (and not on separate
            batches with final averaging).

        Args:
            batch (tuple): tuple of (imgs, responses). The images might be all the
                same in case of the oracle dataset for evaluation of the averaged trial correlation.
            batch_idx (int): Index of the batch

        Returns:
            tuple: (prediction of responses, true responses of each trial (might be averaged), true responses of each trial (never averaged))
        &#34;&#34;&#34;

        img, resp = batch
        responses_no_mean = resp

        if self.test_average_batch:
            # I take only one image as all images are the same (it is a repeated trial)
            # .unsqueeze(0) adds one dimension at the beginning (because I need
            # to create a batch of size 1)
            img = img[0].unsqueeze(0)
            resp = resp.mean(0).unsqueeze(0)

        prediction = self.forward(img)
        return prediction, resp, responses_no_mean

    def configure_optimizers(self):
        &#34;&#34;&#34;Configures the optimizer for the training of the model (Adam).

        Returns:
            torch.optimizer: torch optimizer class
        &#34;&#34;&#34;
        opt = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
        return opt

    def test_epoch_end(self, test_outs):
        &#34;&#34;&#34;We compute a correlation on the WHOLE test set. Predictions with target
        responses are in test_outs (= what each self.test_step() returned)

        Args:
            test_outs (list): What each self.test_step() returned
        &#34;&#34;&#34;
        pred = []
        resp = []
        batch_of_responses = []
        num_of_repeats = None
        for (p, r, r_batches) in test_outs:

            # The number of repeats in the repeated trials have to be the same.
            # We will use the first batch as an indicator, how many trials should
            # be in every batch. If some batch does not have the same number of
            # repeats, we discard the batch
            if num_of_repeats == None:
                num_of_repeats = r_batches.shape[0]

            pred.append(p.detach().cpu().numpy())
            resp.append(r.detach().cpu().numpy())

            if (
                r_batches.shape[0] == num_of_repeats and self.compute_oracle_fraction
            ):  # does not have the appropriate number of repeats
                batch_of_responses.append(r_batches.detach().cpu().numpy())

        predictions = np.concatenate(pred)
        responses = np.concatenate(resp)
        correlation = corr_from_neuralpredictors(predictions, responses, axis=0)

        batches_of_responses = None
        if self.compute_oracle_fraction:
            batches_of_responses = np.stack(batch_of_responses)

        if self.test_average_batch:
            self.log(&#34;test/repeated_trials/corr&#34;, np.mean(correlation))
        else:
            self.log(&#34;test/corr&#34;, np.mean(correlation))

        if self.compute_oracle_fraction:
            if self.jackknife_oracle:
                oracles = oracle_corr_jackknife(batches_of_responses)
                fraction_of_oracles = get_fraction_oracles(
                    oracles,
                    correlation,
                    generate_figure=self.generate_oracle_figure,
                    oracle_label=&#34;Oracles jackknife&#34;,
                    fig_name=&#34;oracle_jackknife.png&#34;,
                )
                self.log(&#34;test/fraction_oracle_jackknife&#34;, fraction_of_oracles[0])

            if self.conservative_oracle:
                oracles = oracle_corr_conservative(batches_of_responses)
                fraction_of_oracles = get_fraction_oracles(
                    oracles,
                    correlation,
                    generate_figure=self.generate_oracle_figure,
                    oracle_label=&#34;Oracles conservative&#34;,
                    fig_name=&#34;oracle_conservative.png&#34;,
                )
                self.log(&#34;test/fraction_oracle_conservative&#34;, fraction_of_oracles[0])

    def validation_epoch_end(self, val_outs):
        &#34;&#34;&#34;We compute the correlation on the whole set. Predictions with target
        responses are in val_outs (= what each val_step() returned)

        Args:
            val_outs (list): What each self.validation_step() returned
        &#34;&#34;&#34;        
        pred = []
        resp = []
        for (p, r) in val_outs:
            pred.append(p.detach().cpu().numpy())
            resp.append(r.detach().cpu().numpy())

        predictions = np.concatenate(pred)
        responses = np.concatenate(resp)
        correlation = corr_from_neuralpredictors(predictions, responses, axis=0)
        self.log(&#34;val/corr&#34;, np.mean(correlation))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li>create_ensemble.AggregateModel</li>
<li><a title="models.LurzReimplementation" href="#models.LurzReimplementation">LurzReimplementation</a></li>
<li><a title="models.Lurz_Control_Model" href="#models.Lurz_Control_Model">Lurz_Control_Model</a></li>
<li><a title="models.reCNN_FullFactorized" href="#models.reCNN_FullFactorized">reCNN_FullFactorized</a></li>
<li><a title="models.reCNN_Gauss2D" href="#models.reCNN_Gauss2D">reCNN_Gauss2D</a></li>
<li><a title="models.reCNN_bottleneck_CyclicGauss3d" href="#models.reCNN_bottleneck_CyclicGauss3d">reCNN_bottleneck_CyclicGauss3d</a></li>
<li><a title="models.reCNN_bottleneck_Gauss2d" href="#models.reCNN_bottleneck_Gauss2d">reCNN_bottleneck_Gauss2d</a></li>
<li><a title="models.reCNN_bottleneck_NoReadout" href="#models.reCNN_bottleneck_NoReadout">reCNN_bottleneck_NoReadout</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.ExtendedEncodingModel.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.ExtendedEncodingModel.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.ExtendedEncodingModel.configure_optimizers"><code class="name flex">
<span>def <span class="ident">configure_optimizers</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Configures the optimizer for the training of the model (Adam).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>torch.optimizer</code></dt>
<dd>torch optimizer class</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_optimizers(self):
    &#34;&#34;&#34;Configures the optimizer for the training of the model (Adam).

    Returns:
        torch.optimizer: torch optimizer class
    &#34;&#34;&#34;
    opt = torch.optim.Adam(self.parameters(), lr=self.config[&#34;lr&#34;])
    return opt</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, *args, **kwargs) ‑> Any</span>
</code></dt>
<dd>
<div class="desc"><p>Same as :meth:<code>torch.nn.Module.forward()</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>*args</code></strong></dt>
<dd>Whatever you decide to pass into the forward method.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments are also possible.</dd>
</dl>
<h2 id="return">Return</h2>
<p>Your model's output</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, *args, **kwargs) -&gt; Any:
    r&#34;&#34;&#34;
    Same as :meth:`torch.nn.Module.forward()`.

    Args:
        *args: Whatever you decide to pass into the forward method.
        **kwargs: Keyword arguments are also possible.

    Return:
        Your model&#39;s output
    &#34;&#34;&#34;
    return super().forward(*args, **kwargs)</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):
    return 0</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.test_epoch_end"><code class="name flex">
<span>def <span class="ident">test_epoch_end</span></span>(<span>self, test_outs)</span>
</code></dt>
<dd>
<div class="desc"><p>We compute a correlation on the WHOLE test set. Predictions with target
responses are in test_outs (= what each self.test_step() returned)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>test_outs</code></strong> :&ensp;<code>list</code></dt>
<dd>What each self.test_step() returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_epoch_end(self, test_outs):
    &#34;&#34;&#34;We compute a correlation on the WHOLE test set. Predictions with target
    responses are in test_outs (= what each self.test_step() returned)

    Args:
        test_outs (list): What each self.test_step() returned
    &#34;&#34;&#34;
    pred = []
    resp = []
    batch_of_responses = []
    num_of_repeats = None
    for (p, r, r_batches) in test_outs:

        # The number of repeats in the repeated trials have to be the same.
        # We will use the first batch as an indicator, how many trials should
        # be in every batch. If some batch does not have the same number of
        # repeats, we discard the batch
        if num_of_repeats == None:
            num_of_repeats = r_batches.shape[0]

        pred.append(p.detach().cpu().numpy())
        resp.append(r.detach().cpu().numpy())

        if (
            r_batches.shape[0] == num_of_repeats and self.compute_oracle_fraction
        ):  # does not have the appropriate number of repeats
            batch_of_responses.append(r_batches.detach().cpu().numpy())

    predictions = np.concatenate(pred)
    responses = np.concatenate(resp)
    correlation = corr_from_neuralpredictors(predictions, responses, axis=0)

    batches_of_responses = None
    if self.compute_oracle_fraction:
        batches_of_responses = np.stack(batch_of_responses)

    if self.test_average_batch:
        self.log(&#34;test/repeated_trials/corr&#34;, np.mean(correlation))
    else:
        self.log(&#34;test/corr&#34;, np.mean(correlation))

    if self.compute_oracle_fraction:
        if self.jackknife_oracle:
            oracles = oracle_corr_jackknife(batches_of_responses)
            fraction_of_oracles = get_fraction_oracles(
                oracles,
                correlation,
                generate_figure=self.generate_oracle_figure,
                oracle_label=&#34;Oracles jackknife&#34;,
                fig_name=&#34;oracle_jackknife.png&#34;,
            )
            self.log(&#34;test/fraction_oracle_jackknife&#34;, fraction_of_oracles[0])

        if self.conservative_oracle:
            oracles = oracle_corr_conservative(batches_of_responses)
            fraction_of_oracles = get_fraction_oracles(
                oracles,
                correlation,
                generate_figure=self.generate_oracle_figure,
                oracle_label=&#34;Oracles conservative&#34;,
                fig_name=&#34;oracle_conservative.png&#34;,
            )
            self.log(&#34;test/fraction_oracle_conservative&#34;, fraction_of_oracles[0])</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.test_step"><code class="name flex">
<span>def <span class="ident">test_step</span></span>(<span>self, batch, batch_idx)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>
<p>If self.test_average_batch == True, then we average the responses of
the batch (because it is the same image shown multiple times to cancel
out the noise)</p>
</li>
<li>
<p>We just get prediction and return them with target. Later in validation_epoch_end,
we compute the correlation on the whole validation set (and not on separate
batches with final averaging).</p>
</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch</code></strong> :&ensp;<code>tuple</code></dt>
<dd>tuple of (imgs, responses). The images might be all the
same in case of the oracle dataset for evaluation of the averaged trial correlation.</dd>
<dt><strong><code>batch_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the batch</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(prediction of responses, true responses of each trial (might be averaged), true responses of each trial (never averaged))</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_step(self, batch, batch_idx):
    &#34;&#34;&#34;
    - If self.test_average_batch == True, then we average the responses of
        the batch (because it is the same image shown multiple times to cancel
        out the noise)

    - We just get prediction and return them with target. Later in validation_epoch_end,
        we compute the correlation on the whole validation set (and not on separate
        batches with final averaging).

    Args:
        batch (tuple): tuple of (imgs, responses). The images might be all the
            same in case of the oracle dataset for evaluation of the averaged trial correlation.
        batch_idx (int): Index of the batch

    Returns:
        tuple: (prediction of responses, true responses of each trial (might be averaged), true responses of each trial (never averaged))
    &#34;&#34;&#34;

    img, resp = batch
    responses_no_mean = resp

    if self.test_average_batch:
        # I take only one image as all images are the same (it is a repeated trial)
        # .unsqueeze(0) adds one dimension at the beginning (because I need
        # to create a batch of size 1)
        img = img[0].unsqueeze(0)
        resp = resp.mean(0).unsqueeze(0)

    prediction = self.forward(img)
    return prediction, resp, responses_no_mean</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.training_step"><code class="name flex">
<span>def <span class="ident">training_step</span></span>(<span>self, batch, batch_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines what to do at each training step.
Gets the batch, passes it through the network, updates weights,
computes loss and regularization, logs important metrics and
returns regularized loss.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch</code></strong> :&ensp;<code>tuple</code></dt>
<dd>tuple of (imgs, responses)</dd>
<dt><strong><code>batch_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the batch</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Regularized loss</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def training_step(self, batch, batch_idx):
    &#34;&#34;&#34;Defines what to do at each training step.
    Gets the batch, passes it through the network, updates weights,
    computes loss and regularization, logs important metrics and
    returns regularized loss.

    Args:
        batch (tuple): tuple of (imgs, responses)
        batch_idx (int): Index of the batch

    Returns:
        float: Regularized loss
    &#34;&#34;&#34;
    img, resp = batch
    prediction = self.forward(img)
    loss = self.loss(prediction, resp)
    reg_term = self.regularization()
    regularized_loss = loss + reg_term
    self.log(&#34;train/unregularized_loss&#34;, loss)
    self.log(&#34;train/regularization&#34;, reg_term)
    self.log(&#34;train/regularized_loss&#34;, regularized_loss)
    return regularized_loss</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.validation_epoch_end"><code class="name flex">
<span>def <span class="ident">validation_epoch_end</span></span>(<span>self, val_outs)</span>
</code></dt>
<dd>
<div class="desc"><p>We compute the correlation on the whole set. Predictions with target
responses are in val_outs (= what each val_step() returned)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>val_outs</code></strong> :&ensp;<code>list</code></dt>
<dd>What each self.validation_step() returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validation_epoch_end(self, val_outs):
    &#34;&#34;&#34;We compute the correlation on the whole set. Predictions with target
    responses are in val_outs (= what each val_step() returned)

    Args:
        val_outs (list): What each self.validation_step() returned
    &#34;&#34;&#34;        
    pred = []
    resp = []
    for (p, r) in val_outs:
        pred.append(p.detach().cpu().numpy())
        resp.append(r.detach().cpu().numpy())

    predictions = np.concatenate(pred)
    responses = np.concatenate(resp)
    correlation = corr_from_neuralpredictors(predictions, responses, axis=0)
    self.log(&#34;val/corr&#34;, np.mean(correlation))</code></pre>
</details>
</dd>
<dt id="models.ExtendedEncodingModel.validation_step"><code class="name flex">
<span>def <span class="ident">validation_step</span></span>(<span>self, batch, batch_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines what to do at each validation step.
We just get prediction and return them with target. Later in self.validation_epoch_end,
we compute the correlation on the whole validation set (and not on separate
batches with final averaging)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch</code></strong> :&ensp;<code>tuple</code></dt>
<dd>tuple of (imgs, responses)</dd>
<dt><strong><code>batch_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the batch</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(prediction of responses, true responses)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validation_step(self, batch, batch_idx):
    &#34;&#34;&#34;Defines what to do at each validation step.
    We just get prediction and return them with target. Later in self.validation_epoch_end,
    we compute the correlation on the whole validation set (and not on separate
    batches with final averaging)

    Args:
        batch (tuple): tuple of (imgs, responses)
        batch_idx (int): Index of the batch

    Returns:
        tuple: (prediction of responses, true responses)
    &#34;&#34;&#34;        

    img, resp = batch
    prediction = self.forward(img)
    loss = self.loss(prediction, resp)
    self.log(&#34;val/loss&#34;, loss)

    return prediction, resp</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="models.LurzReimplementation"><code class="flex name class">
<span>class <span class="ident">LurzReimplementation</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Reimplementation of the original Lurz's model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LurzReimplementation(ExtendedEncodingModel):
    &#34;&#34;&#34;Reimplementation of the original Lurz&#39;s model.&#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = cores.SE2dCore(
            stride=self.config[&#34;stride&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],  # 0
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],  # 0
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;] * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;StackedCore_FullGaussian2d&#34;

    def reg_readout_group_sparsity(self):
        nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.LurzReimplementation.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.LurzReimplementation.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.LurzReimplementation.reg_readout_group_sparsity"><code class="name flex">
<span>def <span class="ident">reg_readout_group_sparsity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reg_readout_group_sparsity(self):
    nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
    reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
        torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
    )
    return reg_term</code></pre>
</details>
</dd>
<dt id="models.LurzReimplementation.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

    readout_reg = readout_l1_reg
    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.Lurz_Control_Model"><code class="flex name class">
<span>class <span class="ident">Lurz_Control_Model</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Lurz's model used as a control model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Lurz_Control_Model(ExtendedEncodingModel):
    &#34;&#34;&#34;Lurz&#39;s model used as a control model&#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        # self.loss = PoissonLoss(avg=True)
        # self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]
        

        self.core = cores.SE2dCore(
            stride=self.config[&#34;stride&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;], # 0
            gamma_hidden=config[&#34;core_gamma_hidden&#34;], # 0
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;]
        )

        
        self.readout = readouts.FullGaussian2d(
            in_shape=( #TODO: stack???
                #TODO: ten shape si potvrdit
                self.config[&#34;core_hidden_channels&#34;] * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;], # ocividne se to padduje, takze to neztraci rozmery
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x
    
    def __str__(self):
        return &#34;StackedCore_FullGaussian2d&#34;
    

    def reg_readout_group_sparsity(self):
        nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.Lurz_Control_Model.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.Lurz_Control_Model.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.Lurz_Control_Model.reg_readout_group_sparsity"><code class="name flex">
<span>def <span class="ident">reg_readout_group_sparsity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reg_readout_group_sparsity(self):
    nw = self.readout.features.reshape(self.config[&#34;num_neurons&#34;], -1)
    reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
        torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
    )
    return reg_term</code></pre>
</details>
</dd>
<dt id="models.Lurz_Control_Model.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

    readout_reg = readout_l1_reg
    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.reCNN_FullFactorized"><code class="flex name class">
<span>class <span class="ident">reCNN_FullFactorized</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotation-equivariant CNN with a Full factorized readout.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reCNN_FullFactorized(ExtendedEncodingModel):
    &#34;&#34;&#34;Rotation-equivariant CNN with a Full factorized readout.
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = cores.RotationEquivariant2dCore(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullFactorized2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;]
                * self.config[&#34;num_rotations&#34;]
                * abs(self.config[&#34;stack&#34;]),
                self.config[
                    &#34;input_size_x&#34;
                ],  # ocividne se to padduje, takze to neztraci rozmery
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            spatial_and_feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_FullFactorized2d&#34;

    def reg_readout_spatial_smoothness(self):
        nw = self.readout.normalized_spatial()
        reg_term = torch.sqrt(
            torch.sum(
                torch.pow(
                    nn.functional.conv2d(
                        nw.reshape(
                            self.config[&#34;num_neurons&#34;],
                            1,
                            self.config[&#34;input_size_x&#34;],
                            self.config[&#34;input_size_y&#34;],
                        ),
                        self.laplace,
                        padding=&#34;same&#34;,
                    ),
                    2,
                )
            )
        )
        reg_term = self.config[&#34;reg_readout_spatial_smoothness&#34;] * reg_term
        return reg_term

    def reg_readout_group_sparsity(self):
        nw = self.readout.normalized_spatial().reshape(self.config[&#34;num_neurons&#34;], -1)
        reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
            torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
        )
        return reg_term

    def reg_readout_spatial_sparsity(self):
        nw = self.readout.normalized_spatial()
        reg_term = self.config[&#34;reg_spatial_sparsity&#34;] * torch.abs(nw).mean()
        self.log(&#34;reg/readout_spatial_sparsity&#34;, reg_term)
        return reg_term

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
        spatial_smoothness = self.reg_readout_spatial_smoothness()
        group_sparsity = self.reg_readout_group_sparsity()
        spatial_sparsity = self.reg_readout_spatial_sparsity()
        self.log(&#34;reg/readout_spatial_smoothness&#34;, spatial_smoothness)
        self.log(&#34;reg/readout_group_sparsity&#34;, group_sparsity)
        self.log(&#34;reg/readout_spatial_sparsity&#34;, spatial_sparsity)

        readout_reg = (
            readout_l1_reg + spatial_smoothness + group_sparsity + spatial_sparsity
        )
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.reCNN_FullFactorized.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.reCNN_FullFactorized.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.reCNN_FullFactorized.reg_readout_group_sparsity"><code class="name flex">
<span>def <span class="ident">reg_readout_group_sparsity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reg_readout_group_sparsity(self):
    nw = self.readout.normalized_spatial().reshape(self.config[&#34;num_neurons&#34;], -1)
    reg_term = self.config[&#34;reg_group_sparsity&#34;] * torch.sum(
        torch.sqrt(torch.sum(torch.pow(nw, 2), dim=-1)), 0
    )
    return reg_term</code></pre>
</details>
</dd>
<dt id="models.reCNN_FullFactorized.reg_readout_spatial_smoothness"><code class="name flex">
<span>def <span class="ident">reg_readout_spatial_smoothness</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reg_readout_spatial_smoothness(self):
    nw = self.readout.normalized_spatial()
    reg_term = torch.sqrt(
        torch.sum(
            torch.pow(
                nn.functional.conv2d(
                    nw.reshape(
                        self.config[&#34;num_neurons&#34;],
                        1,
                        self.config[&#34;input_size_x&#34;],
                        self.config[&#34;input_size_y&#34;],
                    ),
                    self.laplace,
                    padding=&#34;same&#34;,
                ),
                2,
            )
        )
    )
    reg_term = self.config[&#34;reg_readout_spatial_smoothness&#34;] * reg_term
    return reg_term</code></pre>
</details>
</dd>
<dt id="models.reCNN_FullFactorized.reg_readout_spatial_sparsity"><code class="name flex">
<span>def <span class="ident">reg_readout_spatial_sparsity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reg_readout_spatial_sparsity(self):
    nw = self.readout.normalized_spatial()
    reg_term = self.config[&#34;reg_spatial_sparsity&#34;] * torch.abs(nw).mean()
    self.log(&#34;reg/readout_spatial_sparsity&#34;, reg_term)
    return reg_term</code></pre>
</details>
</dd>
<dt id="models.reCNN_FullFactorized.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
    spatial_smoothness = self.reg_readout_spatial_smoothness()
    group_sparsity = self.reg_readout_group_sparsity()
    spatial_sparsity = self.reg_readout_spatial_sparsity()
    self.log(&#34;reg/readout_spatial_smoothness&#34;, spatial_smoothness)
    self.log(&#34;reg/readout_group_sparsity&#34;, group_sparsity)
    self.log(&#34;reg/readout_spatial_sparsity&#34;, spatial_sparsity)

    readout_reg = (
        readout_l1_reg + spatial_smoothness + group_sparsity + spatial_sparsity
    )
    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.reCNN_Gauss2D"><code class="flex name class">
<span>class <span class="ident">reCNN_Gauss2D</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotation-equivariant CNN with a 2d Gaussian readout.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reCNN_Gauss2D(ExtendedEncodingModel):
    &#34;&#34;&#34;Rotation-equivariant CNN with a 2d Gaussian readout.
    &#34;&#34;&#34;
    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.loss = PoissonLoss(avg=True)
        self.corr = Corr()
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.core = RotationEquivariant2dCore(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;core_hidden_channels&#34;]
                * self.config[&#34;num_rotations&#34;]
                * abs(self.config[&#34;stack&#34;]),
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_FullGaussian2d&#34;

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
        readout_reg = readout_l1_reg
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.reCNN_Gauss2D.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.reCNN_Gauss2D.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.reCNN_Gauss2D.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)
    readout_reg = readout_l1_reg
    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.reCNN_bottleneck_CyclicGauss3d"><code class="flex name class">
<span>class <span class="ident">reCNN_bottleneck_CyclicGauss3d</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>The main model of this repository.
This model consists of:
- a core with reCNN architecture with a bottleneck in the last layer
to return only one scalar value for each position and orientation
(meaning that the number of channels in the last layer is limited
to 1)
- a readout which is a Gaussian 3d readout but modified in a way
that ensures that the third dimension (= orientation dimension)
is periodic</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reCNN_bottleneck_CyclicGauss3d(ExtendedEncodingModel):
    &#34;&#34;&#34;
        The main model of this repository.
        This model consists of:
            - a core with reCNN architecture with a bottleneck in the last layer
              to return only one scalar value for each position and orientation
              (meaning that the number of channels in the last layer is limited
              to 1)
            - a readout which is a Gaussian 3d readout but modified in a way
              that ensures that the third dimension (= orientation dimension)
              is periodic
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.readout = Gaussian3dCyclic(
            in_shape=(
                self.config[&#34;num_rotations&#34;],
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
            init_sigma_range=self.config[&#34;init_sigma_range&#34;],
            init_mu_range=self.config[&#34;init_mu_range&#34;],
            fixed_sigma=self.config[&#34;fixed_sigma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        self.log(&#34;train/sigma1&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma1b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        self.log(&#34;train/sigma2&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma2b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        self.log(&#34;train/sigma3&#34;, self.readout.sigma[0, 0, 0, 0, 1])
        self.log(&#34;train/sigma3b&#34;, self.readout.sigma[0, 0, 1, 0, 1])
        # print(self.readout.sigma.shape)
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_CyclicGauss3d&#34;

    def add_bottleneck(self):

        layer = OrderedDict()

        if self.hidden_padding is None:
            self.hidden_padding = self.bottleneck_kernel // 2

        layer[&#34;hermite_conv&#34;] = HermiteConv2D(
            input_features=self.config[&#34;hidden_channels&#34;]
            * self.config[&#34;num_rotations&#34;],
            output_features=1,
            num_rotations=self.config[&#34;num_rotations&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            filter_size=self.config[&#34;bottleneck_kernel&#34;],
            stride=self.config[&#34;stride&#34;],
            padding=self.hidden_padding,
            first_layer=False,
        )
        super().add_bn_layer(layer)
        super().add_activation(layer)
        super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg

        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.reCNN_bottleneck_CyclicGauss3d.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.reCNN_bottleneck_CyclicGauss3d.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.reCNN_bottleneck_CyclicGauss3d.add_bottleneck"><code class="name flex">
<span>def <span class="ident">add_bottleneck</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_bottleneck(self):

    layer = OrderedDict()

    if self.hidden_padding is None:
        self.hidden_padding = self.bottleneck_kernel // 2

    layer[&#34;hermite_conv&#34;] = HermiteConv2D(
        input_features=self.config[&#34;hidden_channels&#34;]
        * self.config[&#34;num_rotations&#34;],
        output_features=1,
        num_rotations=self.config[&#34;num_rotations&#34;],
        upsampling=self.config[&#34;upsampling&#34;],
        filter_size=self.config[&#34;bottleneck_kernel&#34;],
        stride=self.config[&#34;stride&#34;],
        padding=self.hidden_padding,
        first_layer=False,
    )
    super().add_bn_layer(layer)
    super().add_activation(layer)
    super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))</code></pre>
</details>
</dd>
<dt id="models.reCNN_bottleneck_CyclicGauss3d.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

    readout_reg = readout_l1_reg

    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.reCNN_bottleneck_Gauss2d"><code class="flex name class">
<span>class <span class="ident">reCNN_bottleneck_Gauss2d</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>DNN network composed of reCNN core, bottleneck at the end,
and also a FullGaussian2d readout</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reCNN_bottleneck_Gauss2d(ExtendedEncodingModel):
    &#34;&#34;&#34;
    DNN network composed of reCNN core, bottleneck at the end,
    and also a FullGaussian2d readout
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.readout = readouts.FullGaussian2d(
            in_shape=(
                self.config[&#34;num_rotations&#34;],
                self.config[&#34;input_size_x&#34;],
                self.config[&#34;input_size_y&#34;],
            ),
            outdims=self.config[&#34;num_neurons&#34;],
            bias=self.config[&#34;readout_bias&#34;],
            mean_activity=self.config[&#34;mean_activity&#34;],
            feature_reg_weight=self.config[&#34;readout_gamma&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        x = self.nonlin(self.readout(x))
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_Gauss2d&#34;

    def add_bottleneck(self):

        layer = OrderedDict()

        if self.hidden_padding is None:
            self.hidden_padding = self.bottleneck_kernel // 2

        layer[&#34;hermite_conv&#34;] = HermiteConv2D(
            input_features=self.config[&#34;hidden_channels&#34;]
            * self.config[&#34;num_rotations&#34;],
            output_features=1,
            num_rotations=self.config[&#34;num_rotations&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            filter_size=self.config[&#34;bottleneck_kernel&#34;],
            stride=self.config[&#34;stride&#34;],
            padding=self.hidden_padding,
            first_layer=False,
        )
        super().add_bn_layer(layer)
        super().add_activation(layer)
        super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))

    def regularization(self):

        readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
        self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

        readout_reg = readout_l1_reg

        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        self.log(&#34;reg/readout_reg&#34;, readout_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.reCNN_bottleneck_Gauss2d.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.reCNN_bottleneck_Gauss2d.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.reCNN_bottleneck_Gauss2d.add_bottleneck"><code class="name flex">
<span>def <span class="ident">add_bottleneck</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_bottleneck(self):

    layer = OrderedDict()

    if self.hidden_padding is None:
        self.hidden_padding = self.bottleneck_kernel // 2

    layer[&#34;hermite_conv&#34;] = HermiteConv2D(
        input_features=self.config[&#34;hidden_channels&#34;]
        * self.config[&#34;num_rotations&#34;],
        output_features=1,
        num_rotations=self.config[&#34;num_rotations&#34;],
        upsampling=self.config[&#34;upsampling&#34;],
        filter_size=self.config[&#34;bottleneck_kernel&#34;],
        stride=self.config[&#34;stride&#34;],
        padding=self.hidden_padding,
        first_layer=False,
    )
    super().add_bn_layer(layer)
    super().add_activation(layer)
    super().features.add_module(&#34;bottleneck&#34;, nn.Sequential(layer))</code></pre>
</details>
</dd>
<dt id="models.reCNN_bottleneck_Gauss2d.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_l1_reg = self.readout.regularizer(reduction=&#34;mean&#34;)
    self.log(&#34;reg/readout_l1_reg&#34;, readout_l1_reg)

    readout_reg = readout_l1_reg

    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    self.log(&#34;reg/readout_reg&#34;, readout_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="models.reCNN_bottleneck_NoReadout"><code class="flex name class">
<span>class <span class="ident">reCNN_bottleneck_NoReadout</span></span>
<span>(</span><span>**config)</span>
</code></dt>
<dd>
<div class="desc"><p>Lurz's model with RotEq core and with bottleneck
No Readout is present here. It is used to test that the features are
really rotation equivariant (in bottleneck_test.py)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reCNN_bottleneck_NoReadout(ExtendedEncodingModel):
    &#34;&#34;&#34;
    Lurz&#39;s model with RotEq core and with bottleneck
    No Readout is present here. It is used to test that the features are
        really rotation equivariant (in bottleneck_test.py)
    &#34;&#34;&#34;

    def __init__(self, **config):
        super().__init__(**config)
        self.config = config
        self.nonlinearity = self.config[&#34;nonlinearity&#34;]

        self.hidden_padding = None
        assert self.config[&#34;stack&#34;] == -1

        self.core = RotationEquivariant2dCoreBottleneck(
            num_rotations=self.config[&#34;num_rotations&#34;],
            stride=self.config[&#34;stride&#34;],
            upsampling=self.config[&#34;upsampling&#34;],
            rot_eq_batch_norm=self.config[&#34;rot_eq_batch_norm&#34;],
            input_regularizer=self.config[&#34;input_regularizer&#34;],
            input_channels=self.config[&#34;input_channels&#34;],
            hidden_channels=self.config[&#34;core_hidden_channels&#34;],
            input_kern=self.config[&#34;core_input_kern&#34;],
            hidden_kern=self.config[&#34;core_hidden_kern&#34;],
            layers=self.config[&#34;core_layers&#34;],
            gamma_input=config[&#34;core_gamma_input&#34;],
            gamma_hidden=config[&#34;core_gamma_hidden&#34;],
            stack=config[&#34;stack&#34;],
            depth_separable=config[&#34;depth_separable&#34;],
            use_avg_reg=config[&#34;use_avg_reg&#34;],
            bottleneck_kernel=config[&#34;bottleneck_kernel&#34;],
        )

        self.register_buffer(&#34;laplace&#34;, torch.from_numpy(laplace()))
        self.nonlin = bl.act_func()[config[&#34;nonlinearity&#34;]]

    def forward(self, x):
        x = self.core(x)
        return x

    def __str__(self):
        return &#34;reCNN_bottleneck_NoReadout&#34;

    def regularization(self):

        readout_reg = 0
        core_reg = self.core.regularizer()
        reg_term = readout_reg + core_reg
        self.log(&#34;reg/core reg&#34;, core_reg)
        return reg_term</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></li>
<li>predict_neural_responses.models.encoding_model</li>
<li>pytorch_lightning.core.lightning.LightningModule</li>
<li>pytorch_lightning.core.mixins.device_dtype_mixin.DeviceDtypeModuleMixin</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
<li>pytorch_lightning.core.saving.ModelIO</li>
<li>pytorch_lightning.core.hooks.ModelHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="models.reCNN_bottleneck_NoReadout.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="models.reCNN_bottleneck_NoReadout.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="models.reCNN_bottleneck_NoReadout.regularization"><code class="name flex">
<span>def <span class="ident">regularization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regularization(self):

    readout_reg = 0
    core_reg = self.core.regularizer()
    reg_term = readout_reg + core_reg
    self.log(&#34;reg/core reg&#34;, core_reg)
    return reg_term</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></b></code>:
<ul class="hlist">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="models.ExtendedEncodingModel" href="#models.ExtendedEncodingModel">ExtendedEncodingModel</a></code></h4>
<ul class="">
<li><code><a title="models.ExtendedEncodingModel.configure_optimizers" href="#models.ExtendedEncodingModel.configure_optimizers">configure_optimizers</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.dump_patches" href="#models.ExtendedEncodingModel.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.forward" href="#models.ExtendedEncodingModel.forward">forward</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.regularization" href="#models.ExtendedEncodingModel.regularization">regularization</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_epoch_end" href="#models.ExtendedEncodingModel.test_epoch_end">test_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.test_step" href="#models.ExtendedEncodingModel.test_step">test_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training" href="#models.ExtendedEncodingModel.training">training</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.training_step" href="#models.ExtendedEncodingModel.training_step">training_step</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_epoch_end" href="#models.ExtendedEncodingModel.validation_epoch_end">validation_epoch_end</a></code></li>
<li><code><a title="models.ExtendedEncodingModel.validation_step" href="#models.ExtendedEncodingModel.validation_step">validation_step</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.LurzReimplementation" href="#models.LurzReimplementation">LurzReimplementation</a></code></h4>
<ul class="">
<li><code><a title="models.LurzReimplementation.dump_patches" href="#models.LurzReimplementation.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.LurzReimplementation.reg_readout_group_sparsity" href="#models.LurzReimplementation.reg_readout_group_sparsity">reg_readout_group_sparsity</a></code></li>
<li><code><a title="models.LurzReimplementation.regularization" href="#models.LurzReimplementation.regularization">regularization</a></code></li>
<li><code><a title="models.LurzReimplementation.training" href="#models.LurzReimplementation.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.Lurz_Control_Model" href="#models.Lurz_Control_Model">Lurz_Control_Model</a></code></h4>
<ul class="">
<li><code><a title="models.Lurz_Control_Model.dump_patches" href="#models.Lurz_Control_Model.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.Lurz_Control_Model.reg_readout_group_sparsity" href="#models.Lurz_Control_Model.reg_readout_group_sparsity">reg_readout_group_sparsity</a></code></li>
<li><code><a title="models.Lurz_Control_Model.regularization" href="#models.Lurz_Control_Model.regularization">regularization</a></code></li>
<li><code><a title="models.Lurz_Control_Model.training" href="#models.Lurz_Control_Model.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.reCNN_FullFactorized" href="#models.reCNN_FullFactorized">reCNN_FullFactorized</a></code></h4>
<ul class="">
<li><code><a title="models.reCNN_FullFactorized.dump_patches" href="#models.reCNN_FullFactorized.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.reCNN_FullFactorized.reg_readout_group_sparsity" href="#models.reCNN_FullFactorized.reg_readout_group_sparsity">reg_readout_group_sparsity</a></code></li>
<li><code><a title="models.reCNN_FullFactorized.reg_readout_spatial_smoothness" href="#models.reCNN_FullFactorized.reg_readout_spatial_smoothness">reg_readout_spatial_smoothness</a></code></li>
<li><code><a title="models.reCNN_FullFactorized.reg_readout_spatial_sparsity" href="#models.reCNN_FullFactorized.reg_readout_spatial_sparsity">reg_readout_spatial_sparsity</a></code></li>
<li><code><a title="models.reCNN_FullFactorized.regularization" href="#models.reCNN_FullFactorized.regularization">regularization</a></code></li>
<li><code><a title="models.reCNN_FullFactorized.training" href="#models.reCNN_FullFactorized.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.reCNN_Gauss2D" href="#models.reCNN_Gauss2D">reCNN_Gauss2D</a></code></h4>
<ul class="">
<li><code><a title="models.reCNN_Gauss2D.dump_patches" href="#models.reCNN_Gauss2D.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.reCNN_Gauss2D.regularization" href="#models.reCNN_Gauss2D.regularization">regularization</a></code></li>
<li><code><a title="models.reCNN_Gauss2D.training" href="#models.reCNN_Gauss2D.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.reCNN_bottleneck_CyclicGauss3d" href="#models.reCNN_bottleneck_CyclicGauss3d">reCNN_bottleneck_CyclicGauss3d</a></code></h4>
<ul class="">
<li><code><a title="models.reCNN_bottleneck_CyclicGauss3d.add_bottleneck" href="#models.reCNN_bottleneck_CyclicGauss3d.add_bottleneck">add_bottleneck</a></code></li>
<li><code><a title="models.reCNN_bottleneck_CyclicGauss3d.dump_patches" href="#models.reCNN_bottleneck_CyclicGauss3d.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.reCNN_bottleneck_CyclicGauss3d.regularization" href="#models.reCNN_bottleneck_CyclicGauss3d.regularization">regularization</a></code></li>
<li><code><a title="models.reCNN_bottleneck_CyclicGauss3d.training" href="#models.reCNN_bottleneck_CyclicGauss3d.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.reCNN_bottleneck_Gauss2d" href="#models.reCNN_bottleneck_Gauss2d">reCNN_bottleneck_Gauss2d</a></code></h4>
<ul class="">
<li><code><a title="models.reCNN_bottleneck_Gauss2d.add_bottleneck" href="#models.reCNN_bottleneck_Gauss2d.add_bottleneck">add_bottleneck</a></code></li>
<li><code><a title="models.reCNN_bottleneck_Gauss2d.dump_patches" href="#models.reCNN_bottleneck_Gauss2d.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.reCNN_bottleneck_Gauss2d.regularization" href="#models.reCNN_bottleneck_Gauss2d.regularization">regularization</a></code></li>
<li><code><a title="models.reCNN_bottleneck_Gauss2d.training" href="#models.reCNN_bottleneck_Gauss2d.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="models.reCNN_bottleneck_NoReadout" href="#models.reCNN_bottleneck_NoReadout">reCNN_bottleneck_NoReadout</a></code></h4>
<ul class="">
<li><code><a title="models.reCNN_bottleneck_NoReadout.dump_patches" href="#models.reCNN_bottleneck_NoReadout.dump_patches">dump_patches</a></code></li>
<li><code><a title="models.reCNN_bottleneck_NoReadout.regularization" href="#models.reCNN_bottleneck_NoReadout.regularization">regularization</a></code></li>
<li><code><a title="models.reCNN_bottleneck_NoReadout.training" href="#models.reCNN_bottleneck_NoReadout.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>